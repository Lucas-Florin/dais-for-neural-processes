---
# Slurm bwuni cpu
name: "SLURM"   # MUST BE "SLURM"
partition: "single"  # "single" for cpu, "gpu_4" or gpu_8" for gpu
job-name: "baseline" # this will be the experiment's name in slurm
path_to_template: scripts/sbatch_template_bwuni_simple.sh
num_parallel_jobs: 50 # max number of jobs executed in parallel
ntasks: 1   #  leave that like it is
cpus-per-task: 1   # there are 10 cores for each GPU
time: 4000   # in minutes

---
name: "DEFAULT"
# Required: Can also be set in DEFAULT
path: "./experiments/"   # location to save results in
repetitions: 1    # number of agents wandb should initialize

# if there should be multiple agents on one job, select a number > 1. Choose the same number for both options 'reps_per_job' and 'reps_in_parallel'
reps_per_job: 1
reps_in_parallel: 1
iterations: 1
params:
  copy_sweep_model_params: []
  model_params:
    seed: 1234
    d_z: 29
    n_context: [1, 15]
    aggregator_type: "BA"
    loss_type: "MC"
    input_mlp_std_y: ""
    self_attention_type: "None"
    f_act: "relu"
    n_hidden_layers: 2
    n_hidden_units: 26
    latent_prior_scale: 1.0
    decoder_output_scale: 0.1
    device: "cpu"
    adam_lr: 0.0001199
    n_samples: 16
    dais_n_annealing_steps: 10
    dais_step_size: 0.08
    dais_partial: True
    dais_schedule: 'linear'

  train_params:
    n_tasks_train: 2**21
    validation_interval: 2**17
    save_model: False
    load_model: False
    load_model_path: null

  copy_sweep_eval_params: []
  eval_params:
    use_mc: True
    mc_n_samples: 10000
    mc_batch_size: 16

    use_ais: False
    ais_n_samples: 10
    ais_chain_length: 100
    ais_n_hmc_steps: 10
    ais_total_compute: null
    ais_step_size: 0.01

    use_dais: False
    dais_n_samples: 10
    dais_chain_length: 1000
    # dais_n_hmc_steps: 10
    dais_step_size: 0.01

    context_sizes: [0, 1, 2, 4, 6, 8, 12, 16]

    show_examples: True
    example_context_set_sizes: [0, 2, 8]
    example_num_tasks: 4

  benchmark_params:
    benchmark: "Quadratic1D"
    data_noise_std: 0.1
    n_task_meta: 64
    n_datapoints_per_task_meta: 16
    seed_task_meta: 1234
    seed_x_meta: 2234
    seed_noise_meta: 3234
    n_task_val: 16
    n_datapoints_per_task_val: 16
    seed_task_val: 1236
    seed_x_val: 2236
    seed_noise_val: 3236
    n_task_test: 256
    n_datapoints_per_task_test: 64
    seed_task_test: 1235
    seed_x_test: 2235
    seed_noise_test: 3235

wandb:
  group: default
  job_type: run
  project: default

---
name: baseline

params:
  eval_params:
    use_ais: False
  train_params:
    save_model: True

wandb:
  group: first_runs
  project: NP_baseline

---
name: baseline_linesine

params:
  eval_params:
    use_ais: True

  train_params:

    save_model: True
  model_params:
    loss_type: MC
    d_z: 9
    n_hidden_units: 56
    adam_lr: 0.00561
    n_context: [1, 15]
  benchmark_params:
    benchmark: "LineSine1D"

wandb:
  group: first_runs
  project: NP_baseline

---
name: baseline_load

params:
  eval_params:
    use_ais: True
    use_dais: False
    use_mc: True
  train_params:
    load_model: True
    load_model_path: "./experiments/baseline/log/rep_00"

wandb:
  group: first_runs
  project: NP_baseline

---
name: dais
params: 
  model_params:
    loss_type: DAIS
    adam_lr: 0.00008259
    d_z: 28
    dais_n_annealing_steps: 6
    dais_partial: true
    dais_schedule: 'curve'
    dais_step_size: 0.003629
    n_hidden_units: 29
  eval_params: 
    use_dais: False
    use_ais: True
  train_params:
    save_model: True

wandb:
  group: first_runs
  project: NP_baseline

---
name: first_sweep
repetitions: 50

params:
  copy_sweep_model_params: ["adam_lr", "d_z", "n_hidden_units"]
  eval_params:
    use_ais: False
    use_dais: False
    show_examples: False
    mc_batch_size: 128
    mc_n_samples: 1000

wandb:
  group: first_sweep
  job_type: sweep
  project: NP_baseline
  sweep_id: new
  hp_combinations_per_agent: 3

wandb_sweep:
  name: first_sweep
  metric: 
    name: mc_objective
    goal: maximize
  method: bayes
  parameters: 
    adam_lr:
      distribution: log_uniform_values
      max: 0.01
      min: 0.00001
    d_z: 
      min: 8
      max: 32
    n_hidden_units:
      min: 8
      max: 64

---
name: first_sweep_repeat
repetitions: 1

params:
  copy_sweep_params: []
  eval_params:
    use_ais: False
    use_dais: False
    show_examples: True
    mc_batch_size: 16
    mc_n_samples: 10000

list:
  model_params:
    adam_lr: [0.0006791, 0.00465, 0.001539, 0.003069, 0.006172]
    d_z: [25, 19, 20, 19, 18]
    n_hidden_units: [39, 15, 27, 9, 11]

grid:
  model_params:
    seed: [1235, 1236, 1237, 1238, 1239]

wandb:
  group: first_multi_seed
  job_type: multi_seed
  project: NP_baseline
  hp_combinations_per_agent: 1

---
name: ais_sweep
repetitions: 50

params:
  copy_sweep_eval_params: [ais_step_size, ais_n_samples, ais_n_hmc_steps]
  eval_params:
    use_ais: True
    use_mc: False
    use_dais: False
    show_examples: False
    ais_total_compute: 10000
    ais_chain_length: null
  train_params:
    load_model: True
    load_model_path: "./experiments/baseline/log/rep_00"

wandb:
  group: ais_sweep
  job_type: sweep
  project: NP_baseline
  sweep_id: new
  hp_combinations_per_agent: 3

wandb_sweep:
  name: ais_sweep
  metric: 
    name: ais_objective
    goal: maximize
  method: grid
  parameters: 
    ais_step_size:
      values: [0.1, 0.03, 0.01, 0.003, 0.001]
    ais_n_samples: 
      values: [1, 2, 5, 11, 25, 50]
    ais_n_hmc_steps:
      values: [1, 2, 5, 11, 25, 50]


---
name: dais_sweep
repetitions: 40

params:
  copy_sweep_model_params: ["adam_lr", "d_z", "n_hidden_units", "dais_step_size", "dais_n_annealing_steps", "dais_partial", "dais_schedule"]
  model_params:
    loss_type: DAIS
  benchmark_params:
    benchmark: "LineSine1D"
  eval_params:
    use_ais: False
    use_dais: False
    show_examples: False
    mc_batch_size: 128
    mc_n_samples: 1000

wandb:
  group: dais_sweep_linesine
  job_type: sweep
  project: NP_baseline
  sweep_id: new
  hp_combinations_per_agent: 6

wandb_sweep:
  name: dais_sweep_linesine
  metric: 
    name: mc_objective
    goal: maximize
  method: bayes
  parameters: 
    adam_lr:
      distribution: log_uniform_values
      max: 0.01
      min: 0.00001
    dais_step_size:
      distribution: log_uniform_values
      max: 2.4
      min: 0.0024
    dais_n_annealing_steps:
      min: 1
      max: 10
    d_z: 
      min: 8
      max: 32
    n_hidden_units:
      min: 8
      max: 64
    dais_partial:
      distribution: categorical
      values: [True, False]
    dais_schedule:
      distribution: categorical
      values: ['linear', 'curve']
    

---
name: dais_sweep_repeat
repetitions: 1

params:
  model_params:
    loss_type: DAIS
  benchmark_params:
    benchmark: "LineSine1D"
  eval_params:
    use_ais: False

list:
  model_params:
    adam_lr: [0.003093, 0.0055, 0.007864, 0.009881, 0.009453]
    d_z: [10, 9, 8, 10, 9]
    n_hidden_units: [43, 52, 51, 55, 43]
    dais_step_size: [0.003988, 0.002448, 0.003622, 0.003592, 0.002914]
    dais_n_annealing_steps: [3, 5, 2, 1, 1]
    dais_partial: [false, false, true, true, false]
    dais_schedule: [curve, linear, linear, linear, linear]

grid:
  model_params:
    seed: [1235, 1236, 1237, 1238, 1239]

wandb:
  group: dais_multi_seed_linesine
  job_type: multi_seed
  project: NP_baseline
  hp_combinations_per_agent: 1
    

